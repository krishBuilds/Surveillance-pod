# InternVideo2.5 Configuration

model:
  path: "./models/InternVideo2_5"
  device: "auto"  # auto, cuda, cpu
  precision: "bf16"  # bf16, fp16, fp32
  quantization:
    enable_8bit: true  # Enable 8-bit quantization to save ~50% VRAM
    enable_4bit: false # Enable 4-bit quantization (more aggressive, experimental)
  
inference:
  default_num_frames: 16
  max_tokens: 1024
  temperature: 0.7
  top_p: 0.9
  
  # Frame limits based on quantization and GPU memory (empirically tested)
  frame_limits:
    # RTX 4090 24GB limits - TESTED AND VERIFIED
    bf16_max_frames: 48      # Without quantization (baseline)
    int8_max_frames: 160     # With 8-bit quantization (2.5x increase) - VERIFIED WORKING
    int4_max_frames: 150     # With 4-bit quantization (theoretical) - Architecture limit
    
    # Tested boundaries
    tensor_limit: 160        # Tensor shape architecture limit
    memory_limit: 300        # RTX 4090 VRAM exhaustion point
    
    # Automatic frame selection based on quantization
    auto_select_frames: true # Automatically choose optimal frame count
    
  # FPS sampling limits
  fps_limits:
    max_fps_bf16: 1.6       # Max effective FPS without quantization (48 frames / 30s)
    max_fps_int8: 4.0       # Max effective FPS with 8-bit (120 frames / 30s)
    max_fps_int4: 6.7       # Max effective FPS with 4-bit (200 frames / 30s)
  
paths:
  data_dir: "./data"
  output_dir: "./outputs"
  logs_dir: "./logs"
  
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"